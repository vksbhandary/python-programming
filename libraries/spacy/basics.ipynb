{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenization is the process of breaking down a text into tokens. In english language tokens are words, numeric sequence separated by white space or punctuations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent =\"Pizza is my favourite food. Don't underestimate the power of italian pizza.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = lmodel(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN Pizza\n",
      "AUX is\n",
      "DET my\n",
      "ADJ favourite\n",
      "NOUN food\n",
      "PUNCT .\n",
      "AUX Do\n",
      "PART n't\n",
      "VERB underestimate\n",
      "DET the\n",
      "NOUN power\n",
      "ADP of\n",
      "ADJ italian\n",
      "NOUN pizza\n",
      "PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for i in tokens:\n",
    "    print(i.pos_, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ngram\n",
    "\n",
    "N-grams are fixed length consecutive token sequences occutring in the text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(text, n=2):\n",
    "    #we consider text as string we then tokenize the text using spacy\n",
    "    tokens  = [str(t) for t in lmodel(text.lower())]\n",
    "    tok_len = len(tokens)\n",
    "    return [tokens[i:i+n] for i in range(tok_len-n+1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example of bigram for text in variable `sent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pizza', 'is'],\n",
       " ['is', 'my'],\n",
       " ['my', 'favourite'],\n",
       " ['favourite', 'food'],\n",
       " ['food', '.'],\n",
       " ['.', 'do'],\n",
       " ['do', \"n't\"],\n",
       " [\"n't\", 'underestimate'],\n",
       " ['underestimate', 'the'],\n",
       " ['the', 'power'],\n",
       " ['power', 'of'],\n",
       " ['of', 'italian'],\n",
       " ['italian', 'pizza'],\n",
       " ['pizza', '.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example of trigram for text in variable `sent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pizza', 'is', 'my'],\n",
       " ['is', 'my', 'favourite'],\n",
       " ['my', 'favourite', 'food'],\n",
       " ['favourite', 'food', '.'],\n",
       " ['food', '.', 'do'],\n",
       " ['.', 'do', \"n't\"],\n",
       " ['do', \"n't\", 'underestimate'],\n",
       " [\"n't\", 'underestimate', 'the'],\n",
       " ['underestimate', 'the', 'power'],\n",
       " ['the', 'power', 'of'],\n",
       " ['power', 'of', 'italian'],\n",
       " ['of', 'italian', 'pizza'],\n",
       " ['italian', 'pizza', '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram(sent, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemma\n",
    "\n",
    "Lemmas are root of the words. For example the word `fly` can also be depicted in different forms like `flew`, `flown`, `flying`, etc. All these different words same action. Sometimes inorder to reduce the vocabulary (or improve the inference time) lemmas are used instead of original words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza pizza\n",
      "is be\n",
      "my -PRON-\n",
      "favourite favourite\n",
      "food food\n",
      ". .\n",
      "Do do\n",
      "n't not\n",
      "underestimate underestimate\n",
      "the the\n",
      "power power\n",
      "of of\n",
      "italian italian\n",
      "pizza pizza\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for i in lmodel(sent):\n",
    "    print(str(i), i.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition\n",
    "\n",
    "Spacy can also be used to perform named entity recognition. NER is useful to access information from textual data. Here is the example where nouns are extracted from text using spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The black witch flew over the amazon river, using her broom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = lmodel(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The black witch\n",
      "the amazon river\n",
      "her broom\n"
     ]
    }
   ],
   "source": [
    "for i in doc.noun_chunks:\n",
    "    print(str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
